{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Sparsity II: Compressed Sensing\n",
    "\n",
    "---\n",
    "\n",
    "> Author: <font color='#f78c40'>Samuel Farrens</font>    \n",
    "> Year: 2018  \n",
    "> Email: [samuel.farrens@cea.fr](mailto:samuel.farrens@cea.fr)  \n",
    "> Website: <a href=\"https://sfarrens.github.io\" target=\"_blank\">https://sfarrens.github.io</a>\n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Set-Up](#Set-Up)\n",
    "1. [Introduction](#Introduction)\n",
    " * [Objective](#Objective)\n",
    " * [Nyquist-Shannon Sampling Theorem](#Nyquist-Shannon-Sampling-Theorem)\n",
    " * [Compressed Sensing](#Compressed-Sensing)\n",
    "1. [1D Example](#1D-Example)\n",
    " * [Sparse Signal](#Sparse-Signal)\n",
    " * [Fourier Transform](#Fourier-Transform)\n",
    " * [Observation](#Observation)\n",
    " * [Inverse Problem](#Inverse-Problem)\n",
    " * [Optimisation Algorithm](#Optimisation-Algorithm)\n",
    " * [Gradient](#Gradient)\n",
    " * [Signal Recovery](#Signal-Recovery)\n",
    " * [Performance](#Performance)\n",
    "1. [2D Exercise](#2D-Exercise)\n",
    " * [Problem](#Problem)\n",
    " * [Data](#Data)\n",
    " * [Solutions](#Solutions)\n",
    "1. [Hints](#Hints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Set-Up\n",
    "\n",
    "Here we will import a couple of packages that will be needed throughout the notebook. \n",
    "\n",
    "Users new to Jupyter notebooks should note that cells are executed by pressing <kbd>SHIFT</kbd>+<kbd>ENTER</kbd> (&#x21E7;+ &#x23ce;). See <a href=\"https://jupyter-notebook.readthedocs.io/en/stable/\" target_=\"blanck\">here</a> for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tell Jupyter to display plots in this notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "# Import the numpy package with the alias np.\n",
    "import numpy as np\n",
    "\n",
    "# Import function to set size of figures.\n",
    "from matplotlib.pylab import rcParams\n",
    "\n",
    "# Import interaction module.\n",
    "from ipywidgets.widgets import *\n",
    "\n",
    "# Import tutorial functions.\n",
    "from sparsity_tutorial import plot\n",
    "from sparsity_tutorial.functions import l1_norm, sigma_mad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Python 2 users only\n",
    "# Uncomment the following commands\n",
    "\n",
    "# Import Python 3 behaviour\n",
    "# from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set size of figures.\n",
    "rcParams['figure.figsize'] = (14.0, 8.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "### <font color='blue'>Objective</font>\n",
    "\n",
    "This notebook aims to give a brief introduction to how Compressed Sensing (CS) works in practice without getting into too much mathematical detail. For more comprehensive details please see *e.g.*\n",
    "\n",
    "* <a href=\"https://ieeexplore.ieee.org/document/1580791/\" target_=\"blank\">Candès et al. (2006b)</a>\n",
    "* <a href=\"https://ieeexplore.ieee.org/document/4016283/\" target_=\"blank\">Candès and Tao (2006)</a>\n",
    "* <a href=\"https://ieeexplore.ieee.org/document/1614066/\" target_=\"blank\">Donoho (2006a)</a>\n",
    "\n",
    "### <font color='blue'>Nyquist-Shannon Sampling Theorem</font>\n",
    "\n",
    "The Nyquist-Shannon Sampling Theorem dictates that a bandlimited singal can perfectly be recovered if the sample frequency, $f_s$, (*i.e.* number of sample taken per unit time/space) is at least twice the highest frequency contained in the signal, $f_c$.\n",
    "\n",
    "$$f_s \\geq 2f_c$$\n",
    "\n",
    "In the following cell you can see a sine wave (green dotted line) that we wish to recover. Initially this signal is sampled well below the Nyquist rate (blue dots). The resulting effect, known as aliasing, creates the illusion of a signal with a lower frequency (red line). Try increasing the sampling rate and/or frequency to see what happens.\n",
    "\n",
    "<br>\n",
    "<font color='orange'>INTERACTIVE CELL</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "# YOU SHOULD INTERACT WITH THIS CELL #\n",
    "######################################\n",
    "\n",
    "# function to plot signal of given frequency with a given sampling rate\n",
    "def sampling(sampling_rate, frequency):\n",
    "\n",
    "    t = np.arange(0, 1, 1.0 / sampling_rate)\n",
    "    y = np.sin(2 * np.pi * frequency * t)\n",
    "    plot.stem_plot(y, x_vals=t, title='Aliasing', imag=False, ylim=(-1.1, 1.1), line=True, f=frequency)\n",
    "    \n",
    "sampling_slider = IntSlider(value=9, min=2, max=42, step=1)\n",
    "frequency_slider = IntSlider(value=10, min=1, max=10, step=1)\n",
    "    \n",
    "interact(sampling, sampling_rate=sampling_slider, frequency=frequency_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Compressed Sensing</font>\n",
    "\n",
    "Compressed (or compressive) sensing is a paradigm that allows one to sample certain singals at a rate lower than the Nyquist rate by exploiting the sparsity of the signal in a given domain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1D Example\n",
    "\n",
    "To get a more intuitive understanding of how the principles of CS work we begin with an example of a very simple 1D signal. This example will demonstrate how to recover the signal from a masked observation.\n",
    "\n",
    "### <font color='blue'>Sparse Signal</font>\n",
    "\n",
    "First we define a sparse signal, $\\alpha$, with 128 coefficients of which only 5 have non-zero values (*i.e.* a $k$-sparse singal with $k=5$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full sample size\n",
    "n_samples = 128\n",
    "\n",
    "# number of peaks\n",
    "n_peaks = 5\n",
    "\n",
    "# random seed used to ensure reproducibility of results\n",
    "np.random.seed(0)\n",
    "\n",
    "# generate the singal alpha\n",
    "alpha = np.random.permutation(np.hstack((np.random.randn(n_peaks), np.zeros(n_samples - n_peaks))))\n",
    "\n",
    "# plot real and imaginary components of alpha\n",
    "plot.stem_plot(alpha, title=r'$\\alpha$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Fourier Transform</font>\n",
    "\n",
    "Next we want to generate a new signal $x$ which is the Fourier transform of $\\alpha$. *i.e.*\n",
    "\n",
    "$$x = \\phi\\alpha$$\n",
    "\n",
    "where $\\phi$ is a normalised FFT\n",
    "\n",
    "$$\\phi z = \\frac{1}{\\sqrt{n}} \\mathcal{F}(z)$$\n",
    "\n",
    "and $n$ is the size of the signal. The corresponding inverse operation is\n",
    "\n",
    "$$\\phi^{-1} z = \\sqrt{n} \\mathcal{F}^{-1}(z)$$\n",
    "\n",
    "In the following cell we define functions to compute $\\phi$ and $\\phi^{-1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalised FFT\n",
    "def nfft(data):\n",
    "    \n",
    "    return 1 / np.sqrt(data.size) * np.fft.fftshift(np.fft.fft(np.fft.ifftshift(data)))\n",
    "\n",
    "# normalised inverse FFT\n",
    "def infft(data):\n",
    "\n",
    "    return np.sqrt(data.size) * np.fft.fftshift(np.fft.ifft(np.fft.ifftshift(data)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the functions above to generate the singal $x$.\n",
    "\n",
    "<br>\n",
    "<font color='red'>EXERCISE CELL</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# YOU NEED TO EDIT THIS CELL #\n",
    "##############################\n",
    "\n",
    "# generate signal x\n",
    "x = None\n",
    "\n",
    "# plot real and imaginary components of x\n",
    "if x is not None:\n",
    "    plot.stem_plot(x, title=r'$x$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Observation</font>\n",
    "\n",
    "To simulate a CS problem we need to randomly subsample $x$ in order to generate an observation (or acquisition) $y$. We can do this using a masking operator $H$ that we define in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to mask a signal.\n",
    "def mask_op(signal, mask):\n",
    "\n",
    "    return signal[np.where(mask == 1)[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example we will keep only a quarter of the coefficients in $x$.\n",
    "\n",
    "Define a mask that can be used with above function that will keep only $25\\%$ of the coefficients.\n",
    "\n",
    "<br>\n",
    "<font color='red'>EXERCISE CELL</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# YOU NEED TO EDIT THIS CELL #\n",
    "##############################\n",
    "\n",
    "# set the number of non-zero coefficients retained\n",
    "n_subsamples = None\n",
    "\n",
    "# generate the mask\n",
    "mask = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can model $y$ as \n",
    "\n",
    "$$y = H\\phi\\alpha$$\n",
    "\n",
    "Use the mask you defined to generate the observation $y$.\n",
    "\n",
    "<br>\n",
    "<font color='red'>EXERCISE CELL</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##############################\n",
    "# YOU NEED TO EDIT THIS CELL #\n",
    "##############################\n",
    "\n",
    "# generate the subsampled observation y\n",
    "y = None\n",
    "\n",
    "# plot real and imaginary components of y\n",
    "if y is not None:\n",
    "    plot.stem_plot(y, title='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the signal $y$ is indeed shorter than $x$, however in order to properly visualse this masked signal we need to upsample.\n",
    "\n",
    "Upsampling will simply place zeros at the positions of the coefficients masked in $x$. This operation also constitutes the inverse operation of $H$, which we denote $H^T$ as is defined in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to upsample a signal.\n",
    "def upsample(signal, mask, dtype=complex):\n",
    "\n",
    "    val = np.copy(mask).astype(dtype)\n",
    "    val[val == 1] *= signal\n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can display the upsampled version of $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot real and imaginary components of y\n",
    "if y is not None:\n",
    "    plot.stem_plot(upsample(y, mask), title=r'$H^Ty$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Inverse Problem</font>\n",
    "\n",
    "\n",
    "The problem we aim to solve is to recover the original signal $\\alpha$ from $y$ given that we know both $\\phi$ and $H$. This corresponds to the following optimisation problem\n",
    "\n",
    "$$\\begin{aligned} & \\underset{\\alpha}{\\text{argmin}} & \\frac{1}{2}\\|y-H\\phi\\alpha\\|_2^2 + \\lambda\\|\\alpha\\|_1\\end{aligned}$$\n",
    "\n",
    "where we implement sparse regularisation given that we know a priori that $\\alpha$ is sparse. We can implement $l_1$ regularisation via soft thresholding of the sparse coefficients. For this example we also have to manage the complex coefficients of the signal, which we do using the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for performing soft thresholding with complex coefficients.\n",
    "def soft_thresh(data, threshold):\n",
    "\n",
    "    return np.around(np.maximum((1.0 - threshold / np.maximum(np.finfo(np.float64).eps, np.abs(data))),0.0) * data, \n",
    "                     decimals=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given estimate of $\\alpha$ the optimisation problem provides the cost of the solution. To solve this problem we aim to minimise this cost, which we will cacluate with the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the cost.\n",
    "def cost_func(y, alpha_rec, mask, lambda_val):\n",
    "    \n",
    "    return (0.5 * np.linalg.norm(y - mask_op(nfft(alpha_rec), mask)) ** 2 + lambda_val * l1_norm(alpha_rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Optimisation Algorithm</font>\n",
    "    \n",
    "For this example we will use the forward-backward splitting algorithm with a soft thresholding operation to promote sparse solutions. It has the following form for each iteration\n",
    "\n",
    "$$\\alpha_{n+1} = \\alpha_n - \\gamma * \\nabla F(\\alpha_n)$$\n",
    "$$\\alpha_{n+1} = \\text{ST}_\\lambda(\\alpha_{n+1})$$\n",
    "\n",
    "Where $\\nabla F(\\alpha_n)$ corresponds to the gradient of our optimisation problem. The function we will use to implement the algorithm is provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that performs simple forward backward splitting.\n",
    "def forwardBackward(observation, first_guess, mask, grad, lambda_val, n_iter=300, gamma=1.0, return_cost=False):\n",
    "    \n",
    "    alpha_rec = first_guess\n",
    "    cost = []\n",
    "            \n",
    "    for i in range(n_iter):\n",
    "        \n",
    "        alpha_temp = alpha_rec - gamma * grad(observation, alpha_rec, mask)\n",
    "        alpha_rec = soft_thresh(alpha_temp, lambda_val)\n",
    "        cost.append(cost_func(observation, alpha_rec, mask, lambda_val))\n",
    "    \n",
    "    if return_cost:\n",
    "        return alpha_rec, cost\n",
    "    else:\n",
    "        return alpha_rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Gradient</font>\n",
    "\n",
    "The gradient of the above problem is given by\n",
    "\n",
    "$$\\nabla F(\\alpha) = \\phi^{-1}H^T(H\\phi\\alpha-y)$$\n",
    "\n",
    "write a funciton that implements the gradient calculation.\n",
    "\n",
    "<br>\n",
    "<font color='red'>EXERCISE CELL</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##############################\n",
    "# YOU NEED TO EDIT THIS CELL #\n",
    "##############################\n",
    "\n",
    "# Function to calculate the gradient\n",
    "grad = None\n",
    "\n",
    "# Hint, your function should start like this\n",
    "# def grad(y, alpha_rec, mask):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Signal Recovery</font>\n",
    "\n",
    "Now we can use the forward-backward algorithm to recover $\\alpha$. Notice how the solution improves after a given number of iterations until it converges on a very good reconstruction of $\\alpha$.\n",
    "\n",
    "<br>\n",
    "<font color='orange'>INTERACTIVE CELL</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "######################################\n",
    "# YOU SHOULD INTERACT WITH THIS CELL #\n",
    "######################################\n",
    "\n",
    "# Interactive function to plot the recovered alpha after a given number of iterations\n",
    "def solve(n_iter):\n",
    "    \n",
    "    alpha_rec, cost = forwardBackward(observation=y, first_guess=np.ones(n_samples), mask=mask, grad=grad,\n",
    "                                      lambda_val=0.01, n_iter=n_iter, gamma=1.0, return_cost=True)\n",
    "    \n",
    "    plot.stem_plot(alpha_rec, title=r'$\\hat{\\alpha}$')\n",
    "    plot.cost_plot(cost)\n",
    "        \n",
    "slider = IntSlider(value=1, min=1, max=361, step=40)\n",
    "if grad is not None:\n",
    "    interact(solve, n_iter=slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the solution converges after roughly 200 iterations.\n",
    "\n",
    "### <font color='blue'>Performance</font>\n",
    "\n",
    "Finally, we can test the quality of our solution by comparing our recovered $\\hat{\\alpha}$ with the true $\\alpha$. Notice that the difference between the two signals is extrmeley small even for the imaginary components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# recoved signal after 200 iterations\n",
    "if grad is not None:\n",
    "    alpha_rec = forwardBackward(y, np.ones(n_samples), mask, grad, 0.01, 200, 1.0)\n",
    "\n",
    "# plot real and imaginary components of true alpha - recoved alpha\n",
    "if grad is not None: \n",
    "    plot.stem_plot(alpha - alpha_rec, title=r'$\\alpha - \\hat{\\alpha}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Normalised Mean Squared Error (NMSE) provides a useful measure of the quality of a given signal reconstruction.\n",
    "\n",
    "$$\\text{NMSE} = \\frac{\\|\\hat{z} - z\\|_2^2}{\\|z\\|_2^2}$$\n",
    "\n",
    "This function is implemented as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalised mean squared error\n",
    "def nmse(signal_1, singal_2):\n",
    "    \n",
    "    return (np.linalg.norm(singal_2 - signal_1) ** 2 / np.linalg.norm(signal_1) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this function to test solutions to our minimisation problem.\n",
    "\n",
    "Calculate the NMSE of $\\hat{\\alpha}$ after 10 and 200 iterations.\n",
    "\n",
    "<br>\n",
    "<font color='red'>EXERCISE CELL</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# YOU NEED TO EDIT THIS CELL #\n",
    "##############################\n",
    "\n",
    "#Test NMSE after 10 iterations\n",
    "nmse10 = None\n",
    "if nmse10 is not None:\n",
    "    print('NMSE after 10 iterations:', nmse10)\n",
    "\n",
    "# Test NMSE after 200 iterations\n",
    "nmse200 = None\n",
    "if nmse200 is not None:\n",
    "    print('NMSE after 200 iterations:', nmse200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you see an improvement in the NMSE after an appropriate number of iterations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  2D Exercise\n",
    "\n",
    "Attempt to solve the following problem using the techniques you learned from the first exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Problem</font>\n",
    "\n",
    "An observer with limited time on her detection instrument has been forced to take only few noisy samples of a singal of interest. Fortunately she has been celever and has chosen the samples randomly. She now provides you with her samples and the mask she used to collect her data and asks for help in recoevering the original signal.\n",
    "\n",
    "You, being an expert in sparsity and having some experience with this type of data, know that this signal is sparse in Fourier space. You also know that $\\lambda=0.05$ would be an appropriate value for this problem.\n",
    "\n",
    "The observation can be modelled as\n",
    "\n",
    "$$y = Hx + n$$\n",
    "\n",
    "**Questions and tasks**\n",
    "\n",
    "1. What percentage of the coefficients have been sampled?\n",
    "1. Upsample the observation and display it as an image.\n",
    "1. What is your optimisation problem?\n",
    "1. What is the gradient of this problem?\n",
    "1. Make a first guess for $x$.\n",
    "1. Reconstruct the signal using the Forward-Backward algorithm.\n",
    "1. Display your reconstruction $\\hat{x}$.\n",
    "1. Roughly how many iterations did it take to converge?\n",
    "1. Finally, load the file `data/cs_true_data.npy` to determine the NMSE of your solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Data</font>\n",
    "\n",
    "For this exercise you are given a subsampled noisy observation $y$ and a mask $H$. Your task is to recoever the original image $x$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the true image\n",
    "image_shape = (100, 100)\n",
    "\n",
    "# Load the mask\n",
    "mask2d = np.load('data/cs_mask.npy')\n",
    "\n",
    "# Load the observation\n",
    "y2d = np.load('data/cs_obs_data.npy')\n",
    "\n",
    "# Display the mask H\n",
    "plot.display(mask2d, 'Mask', shape=image_shape, cmap='bone')\n",
    "\n",
    "# Display the observation y\n",
    "plot.display(y2d, r'$y$', shape=(25, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Solutions</font>\n",
    "\n",
    "<font color='red'>EXERCISE:</font> provide your solutions in the cell(s) below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <font color='orange'>Hints</font>\n",
    "\n",
    "** 1D Example Hints**\n",
    "\n",
    "1. The mask should only contain zeros and ones.\n",
    "1. The mask should have the same number of coefficients as the original signal.\n",
    "1. To define $y$ note that $x$ has already been defined. \n",
    "1. To define the gradient make sure you use ALL your operators in the right order.\n",
    "\n",
    "** 2D Exercise Hints **\n",
    "\n",
    "1. You can work out the percentage of coefficients retained using only the mask.\n",
    "1. Note that, although the signal is a 2D image, data have been provided in the form of 1D vectors. Think about how this compares to the 1D example.\n",
    "1. Make sure you display your recovered image in the correct domain.\n",
    "1. If you plot your cost function it should be pretty easy to see when the algorithm converged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Open next notebook ->](./sparsity_3_deconvolution.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
